{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbzBJ1m9FBBb"
      },
      "source": [
        "<center><h1>1-ab: Introduction to Neural Networks</h1></center>\n",
        "\n",
        "<center><h2><a href=\"https://rdfia.github.io/\">Course link</a></h2></center>\n",
        "\n",
        "# Warning :\n",
        "# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "NfnKy8NB8J5e"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/rdfia/rdfia.github.io/raw/master/data/2-ab.zip\n",
        "# !unzip -j 2-ab.zip\n",
        "# !wget https://github.com/rdfia/rdfia.github.io/raw/master/code/2-ab/utils-data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "2vQ_LLdx8J5b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%run 'utils-data.py'\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "dtype = torch.float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48x_ha7f8J5i"
      },
      "source": [
        "# Part 1 : Forward and backward passes \"by hands\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "GtizX1JV8J5n"
      },
      "outputs": [],
      "source": [
        "def init_params(nx, nh, ny):\n",
        "    \"\"\"\n",
        "    nx, nh, ny: integers (dimensions of input, hidden and output layers)\n",
        "    out params: dictionnary\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # fill values for Wh, Wy, bh, by\n",
        "    #initialize randomly with some gaussian functions (not all zero, initialization does matter!)\n",
        "\n",
        "    #All weights will be initialized according to a normal distribution of mean 0 and standard deviation 0.3.\n",
        "    params[\"Wh\"] = torch.randn(nh, nx, device=device, dtype=dtype) * 0.3\n",
        "    params[\"Wy\"] = torch.randn(nh, ny) * 0.3\n",
        "    params[\"bh\"] = torch.zeros(nh, 1)\n",
        "    params[\"by\"] = torch.zeros(ny, 1) \n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_affine_transformation(W, X, b):\n",
        "    \"\"\" \n",
        "    linear transformation: ŷ = f (x) = W x with W a matrix of size ny x nx . This transformation is the standard layer of classical\n",
        "neural networks. As a side note, we often use an affine transformation f (x) = W x + b, where b a vector of\n",
        "size ny .\n",
        "    \"\"\"\n",
        "    return torch.mm(W,X) + b\n",
        "\n",
        "def activation_function_tanh(x):\n",
        "    return torch.tanh(x)\n",
        "\n",
        "def activation_function_softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=0)\n",
        "\n",
        "def activation_function_sigmoid(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "def activation_function_relu(x):\n",
        "    return torch.max(torch.zeros(x.size()), x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "jk-N_Ny67yo-"
      },
      "outputs": [],
      "source": [
        "def forward(params, X):\n",
        "    \"\"\"\n",
        "    params: dictionnary\n",
        "    X: (n_batch, dimension)\n",
        "    \n",
        "    Write the function forward (params, X) which calculates the intermediate steps and the output\n",
        "of the network from an input batch X of size nbatch * nx and weights stored in params and store\n",
        "them in a dictionary. We return the dictionary of intermediate steps and the output Ŷ of the network.\n",
        "Hint: we will use torch.mm for matrix multiplication, and torch.tanh, torch.exp, torch.sum\n",
        "    \"\"\"\n",
        "    bsize = X.size(0) #size nbatch * nx \n",
        "    nh = params['Wh'].size(0) #matrix of weights Wh of size nh × nx\n",
        "    ny = params['Wy'].size(0) #bias vector bh of size nh\n",
        "    outputs = {}\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##   \n",
        "    #####################\n",
        "    # fill values for X, htilde, h, ytilde, yhat\n",
        "    \n",
        "    outputs[\"X\"] = X\n",
        "    # print(\"linear affine transformation to get htilde\")\n",
        "    # print(\"X\", outputs[\"X\"].shape)\n",
        "    # print(\"Wh\",params[\"Wh\"].shape)\n",
        "    # print(\"bh\",params[\"bh\"].shape)\n",
        "    outputs[\"htilde\"] = linear_affine_transformation(params[\"Wh\"], X.T, params[\"bh\"])\n",
        "    outputs[\"h\"] = activation_function_tanh(outputs[\"htilde\"])\n",
        "    # print(\"linear affine transformation to get ytilde\")\n",
        "    # print(\"h\", outputs[\"h\"].shape)\n",
        "    # print(\"Wy\",params[\"Wy\"].shape)\n",
        "    # print(\"by\",params[\"by\"].shape)\n",
        "    outputs[\"ytilde\"] = linear_affine_transformation(outputs[\"h\"].T,params[\"Wy\"], params[\"by\"].T)\n",
        "    outputs[\"yhat\"] = activation_function_softmax(outputs[\"ytilde\"])\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    #output all the intermediate values, useful for computing the gradient during the backward pass later\n",
        "\n",
        "    return outputs['yhat'], outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "-uB0A2b28NZK"
      },
      "outputs": [],
      "source": [
        "def loss_accuracy(Yhat, Y):\n",
        "    \"\"\"\n",
        "    Write the function loss_accuracy (Yhat, Y) which computes the cost function and the precision\n",
        "(rate of good predictions) from an output matrix Ŷ (output of forward ) with respect to a ground\n",
        "truth matrix Y of the same size, and returns the loss L and the precision acc .\n",
        "Note: We will use the _, indsY = torch.max (Y, 1) function which returns the index of the\n",
        "predicted class (or to be predicted) for each example.\n",
        "Hints: torch.mean, torch.max, torch.log, torch.sum\n",
        "    \"\"\"\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "\n",
        "    L = 0\n",
        "    acc = 0 \n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    L= -torch.mean(torch.sum(Y * torch.log(Yhat), dim=1))\n",
        "\n",
        "    # Compute the precision (accuracy)\n",
        "    _, indsY = torch.max(Y, 1)\n",
        "    _, indsYhat = torch.max(Yhat, 1)\n",
        "    correct_predictions = torch.sum(indsY == indsYhat)\n",
        "    acc = torch.mean(correct_predictions.float())\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    return L, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "WWJjdiFe8qi5"
      },
      "outputs": [],
      "source": [
        "def backward(params, outputs, Y):\n",
        "    \"\"\" \n",
        "    Write the function backward (params, outputs, Y) which calculates the gradients of the loss\n",
        "with respect to the parameters and stores them in a dictionary.\n",
        "    \"\"\"\n",
        "    bsize = Y.shape[0]\n",
        "    grads = {}\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # fill values for Wy, Wh, by, bh\n",
        "    #use the formula on the backpropagation sheet\n",
        "\n",
        "\n",
        "    print(\"Wy shape\",params[\"Wy\"].shape)\n",
        "    print(\"Wh shape\",params[\"Wh\"].shape)\n",
        "    print(\"by shape\",params[\"by\"].shape)\n",
        "    print(\"bh shape\",params[\"bh\"].shape)\n",
        "    print(\"h shape\",outputs[\"h\"].shape)\n",
        "    print(\"yhat shape\",outputs[\"yhat\"].shape)\n",
        "\n",
        "    grad_ytilde = outputs[\"yhat\"] - Y\n",
        "    print(\"grad y tilde shape\",grad_ytilde.shape)\n",
        "    grad_htilde =  grad_ytilde.mm(params[\"Wy\"].T) * (1 - outputs[\"h\"] ** 2) # Element-wise multiplication of grad_Y and Wy is done with .mm() function\n",
        "\n",
        "\n",
        "    print(\"grad h tilde shape\",grad_htilde.shape)\n",
        "\n",
        "    grads[\"Wy\"] = grad_ytilde.T.mm(outputs[\"h\"])\n",
        "    grads[\"Wh\"] = grad_htilde.T.mm(outputs[\"X\"])\n",
        "    grads[\"by\"] = grad_ytilde.T\n",
        "    grads[\"bh\"] = grad_htilde.T\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "nAnsISsW9CnH"
      },
      "outputs": [],
      "source": [
        "def sgd(params, grads, eta):\n",
        "    \"\"\"\n",
        "    Write the function sgd (params, grads, eta) which applies a stochastic gradient descent by\n",
        "mini-batch and updates the network parameters from their gradients and the learning step\n",
        "    \"\"\"\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "\n",
        "    params[\"Wh\"] = params[\"Wh\"] - eta * grads[\"Wh\"]\n",
        "    params[\"Wy\"] = params[\"Wy\"] - eta * grads[\"Wy\"]\n",
        "    params[\"bh\"] = params[\"bh\"] - eta * grads[\"bh\"]\n",
        "    params[\"by\"] = params[\"by\"] - eta * grads[\"by\"]\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hifuW5UFA3DZ"
      },
      "source": [
        "## Global learning procedure \"by hands\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "4RSw6bd0-qUe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nx 2\n",
            "nh 10\n",
            "ny 2\n",
            "{'Wh': tensor([[-0.0369, -0.3222],\n",
            "        [ 0.2135,  0.3184],\n",
            "        [ 0.2718,  0.2481],\n",
            "        [-0.1692, -0.0662],\n",
            "        [ 0.1345, -0.0724],\n",
            "        [ 0.0521, -0.1431],\n",
            "        [-0.2252,  0.2022],\n",
            "        [-0.0177, -0.1694],\n",
            "        [-0.0281, -0.4054],\n",
            "        [-0.0799, -0.0647]]), 'Wy': tensor([[ 1.9721e-02,  6.0649e-02],\n",
            "        [-4.7975e-01, -2.6687e-01],\n",
            "        [ 1.5843e-01, -2.7801e-01],\n",
            "        [ 6.5281e-02, -5.7081e-01],\n",
            "        [ 2.2910e-01, -3.2855e-01],\n",
            "        [ 1.9639e-01, -3.2289e-02],\n",
            "        [ 9.4592e-02, -6.9910e-01],\n",
            "        [-6.2097e-01, -2.2233e-05],\n",
            "        [-5.5528e-01,  5.1196e-01],\n",
            "        [ 3.0952e-01,  7.2955e-02]]), 'bh': tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]), 'by': tensor([[0.],\n",
            "        [0.]])}\n",
            "X shape in main torch.Size([10, 2])\n",
            "Y shape in main torch.Size([10, 2])\n",
            "Wy shape torch.Size([10, 2])\n",
            "Wh shape torch.Size([10, 2])\n",
            "by shape torch.Size([2, 1])\n",
            "bh shape torch.Size([10, 1])\n",
            "h shape torch.Size([10, 10])\n",
            "yhat shape torch.Size([10, 2])\n",
            "grad y tilde shape torch.Size([10, 2])\n",
            "grad h tilde shape torch.Size([10, 10])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb Cell 12\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m L, acc \u001b[39m=\u001b[39m loss_accuracy(Yhat, Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# batch backward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m grads \u001b[39m=\u001b[39m backward(params, outputs, Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# gradient descent\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m params \u001b[39m=\u001b[39m sgd(params, grads, eta)\n",
            "\u001b[1;32m/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgrad h tilde shape\u001b[39m\u001b[39m\"\u001b[39m,grad_htilde\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m grads[\u001b[39m\"\u001b[39m\u001b[39mWy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m grad_ytilde\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mmm(outputs[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m grads[\u001b[39m\"\u001b[39m\u001b[39mWh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m grad_htilde\u001b[39m.\u001b[39;49mT\u001b[39m*\u001b[39;49moutputs[\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m grads[\u001b[39m\"\u001b[39m\u001b[39mby\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m grad_ytilde\u001b[39m.\u001b[39mT\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leo/github/rfdia-lectures/1_ab_Intro_to_NNs.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m grads[\u001b[39m\"\u001b[39m\u001b[39mbh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m grad_htilde\u001b[39m.\u001b[39mT\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# init\n",
        "data = CirclesData()\n",
        "data.plot_data()\n",
        "N = data.Xtrain.shape[0]\n",
        "Nbatch = 10\n",
        "nx = data.Xtrain.shape[1]\n",
        "nh = 10\n",
        "ny = data.Ytrain.shape[1]\n",
        "eta = 0.03\n",
        "\n",
        "print(\"nx\", nx)\n",
        "print(\"nh\", nh)\n",
        "print(\"ny\", ny)\n",
        "\n",
        "params = init_params(nx, nh, ny)\n",
        "print (params)\n",
        "\n",
        "curves = [[],[], [], []]\n",
        "\n",
        "# epoch\n",
        "for iteration in range(150):\n",
        "\n",
        "    # permute\n",
        "    perm = np.random.permutation(N)\n",
        "    Xtrain = data.Xtrain[perm, :]\n",
        "    Ytrain = data.Ytrain[perm, :]\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # batches\n",
        "    for j in range(N // Nbatch):\n",
        "\n",
        "        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n",
        "        X = Xtrain[indsBatch, :]\n",
        "        Y = Ytrain[indsBatch, :]\n",
        "\n",
        "        # write the optimization algorithm on the batch (X,Y)\n",
        "        # using the functions: forward, loss_accuracy, backward, sgd\n",
        "\n",
        "        # Batch forward pass\n",
        "        print(\"X shape in main\", X.shape)\n",
        "        print(\"Y shape in main\", Y.shape)\n",
        "        Yhat, outputs = forward(params, X)\n",
        "\n",
        "        # computing the loss on the batch\n",
        "        L, acc = loss_accuracy(Yhat, Y)\n",
        "\n",
        "        # batch backward pass\n",
        "        grads = backward(params, outputs, Y)\n",
        "\n",
        "        # gradient descent\n",
        "        params = sgd(params, grads, eta)\n",
        "\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    #computing and showing the loss and the accuracy on train and test\n",
        "    Yhat_train, _ = forward(params, data.Xtrain)\n",
        "    Yhat_test, _ = forward(params, data.Xtest)\n",
        "    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n",
        "    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n",
        "    Ygrid, _ = forward(params, data.Xgrid)\n",
        "\n",
        "    #showing the decision boundary with plot_data_with_grid\n",
        "    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n",
        "    print(title)\n",
        "    data.plot_data_with_grid(Ygrid, title)\n",
        "\n",
        "    curves[0].append(acctrain)\n",
        "    curves[1].append(acctest)\n",
        "    curves[2].append(Ltrain)\n",
        "    curves[3].append(Ltest)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(curves[0], label=\"acc. train\")\n",
        "plt.plot(curves[1], label=\"acc. test\")\n",
        "plt.plot(curves[2], label=\"loss train\")\n",
        "plt.plot(curves[3], label=\"loss test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrHHH5PL8J54"
      },
      "source": [
        "# Part 2 : Simplification of the backward pass with `torch.autograd`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G4q5zP0CEvB"
      },
      "outputs": [],
      "source": [
        "def init_params(nx, nh, ny):\n",
        "    \"\"\"\n",
        "    nx, nh, ny: integers\n",
        "    out params: dictionnary\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # fill values for Wh, Wy, bh, by\n",
        "    # activaye autograd on the network weights\n",
        "\n",
        "    params[\"Wh\"] = None\n",
        "    params[\"Wy\"] = None\n",
        "    params[\"bh\"] = None\n",
        "    params[\"by\"] = None\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL0tSjpKCyVB"
      },
      "source": [
        "The function `forward` remains unchanged from previous part.\n",
        "\n",
        "The function `backward` is no longer used because of \"autograd\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA4ycHlfBzCK"
      },
      "outputs": [],
      "source": [
        "def sgd(params, eta):\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # update the network weights\n",
        "    # warning: use torch.no_grad()\n",
        "    # and reset to zero the gradient accumulators\n",
        "\n",
        "    params[\"Wh\"] = None\n",
        "    params[\"Wy\"] = None\n",
        "    params[\"bh\"] = None\n",
        "    params[\"by\"] = None\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjgcmgQpDfOb"
      },
      "source": [
        "## Global learning procedure with autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p5oR3EqDea-"
      },
      "outputs": [],
      "source": [
        "# init\n",
        "data = CirclesData()\n",
        "data.plot_data()\n",
        "N = data.Xtrain.shape[0]\n",
        "Nbatch = 10\n",
        "nx = data.Xtrain.shape[1]\n",
        "nh = 10\n",
        "ny = data.Ytrain.shape[1]\n",
        "eta = 0.03\n",
        "\n",
        "params = init_params(nx, nh, ny)\n",
        "\n",
        "curves = [[],[], [], []]\n",
        "\n",
        "# epoch\n",
        "for iteration in range(150):\n",
        "\n",
        "    # permute\n",
        "    perm = np.random.permutation(N)\n",
        "    Xtrain = data.Xtrain[perm, :]\n",
        "    Ytrain = data.Ytrain[perm, :]\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # batches\n",
        "    for j in range(N // Nbatch):\n",
        "\n",
        "        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n",
        "        X = Xtrain[indsBatch, :]\n",
        "        Y = Ytrain[indsBatch, :]\n",
        "\n",
        "        # write the optimization algorithm on the batch (X,Y)\n",
        "        # using the functions: forward, loss_accuracy, sgd\n",
        "        # and the backward function with autograd\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "\n",
        "    Yhat_train, _ = forward(params, data.Xtrain)\n",
        "    Yhat_test, _ = forward(params, data.Xtest)\n",
        "    Ltrain, acctrain = loss_accuracy(Yhat_train, data.Ytrain)\n",
        "    Ltest, acctest = loss_accuracy(Yhat_test, data.Ytest)\n",
        "    Ygrid, _ = forward(params, data.Xgrid)\n",
        "\n",
        "    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n",
        "    print(title)\n",
        "    # detach() is used to remove the predictions from the computational graph in autograd\n",
        "    data.plot_data_with_grid(Ygrid.detach(), title)\n",
        "\n",
        "    curves[0].append(acctrain)\n",
        "    curves[1].append(acctest)\n",
        "    curves[2].append(Ltrain)\n",
        "    curves[3].append(Ltest)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(curves[0], label=\"acc. train\")\n",
        "plt.plot(curves[1], label=\"acc. test\")\n",
        "plt.plot(curves[2], label=\"loss train\")\n",
        "plt.plot(curves[3], label=\"loss test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FV1iss68J6H"
      },
      "source": [
        "# Part 3 : Simplification of the forward pass with `torch.nn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6T5Uq7JEl47"
      },
      "source": [
        "`init_params` and `forward` are replaced by the `init_model` function which defines the network architecture and the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-h4r-FH8J6I"
      },
      "outputs": [],
      "source": [
        "def init_model(nx, nh, ny):\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "\n",
        "    model = None\n",
        "    loss = None\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    return model, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geE_TI96FXnl"
      },
      "outputs": [],
      "source": [
        "def loss_accuracy(loss, Yhat, Y):\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # call the loss function\n",
        "\n",
        "    L = 0\n",
        "    acc = 0\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    return L, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e93bvFiYGKnA"
      },
      "outputs": [],
      "source": [
        "def sgd(model, eta):\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # update the network weights\n",
        "    # warning: use torch.no_grad()\n",
        "    # and reset to zero the gradient accumulators\n",
        "\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOxBMmD4Gxtp"
      },
      "source": [
        "## Global learning procedure with autograd and `torch.nn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hMBmCNvHCLn"
      },
      "outputs": [],
      "source": [
        "# init\n",
        "data = CirclesData()\n",
        "data.plot_data()\n",
        "N = data.Xtrain.shape[0]\n",
        "Nbatch = 10\n",
        "nx = data.Xtrain.shape[1]\n",
        "nh = 10\n",
        "ny = data.Ytrain.shape[1]\n",
        "eta = 0.03\n",
        "\n",
        "model, loss = init_model(nx, nh, ny)\n",
        "\n",
        "curves = [[],[], [], []]\n",
        "\n",
        "# epoch\n",
        "for iteration in range(150):\n",
        "\n",
        "    # permute\n",
        "    perm = np.random.permutation(N)\n",
        "    Xtrain = data.Xtrain[perm, :]\n",
        "    Ytrain = data.Ytrain[perm, :]\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "    # batches\n",
        "    for j in range(N // Nbatch):\n",
        "\n",
        "        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n",
        "        X = Xtrain[indsBatch, :]\n",
        "        Y = Ytrain[indsBatch, :]\n",
        "\n",
        "        # write the optimization algorithm on the batch (X,Y)\n",
        "        # using the functions: loss_accuracy, sgd\n",
        "        # the forward with the predict method from the model\n",
        "        # and the backward function with autograd\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "\n",
        "    Yhat_train = model(data.Xtrain)\n",
        "    Yhat_test = model(data.Xtest)\n",
        "    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n",
        "    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n",
        "    Ygrid = model(data.Xgrid)\n",
        "\n",
        "    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n",
        "    print(title)\n",
        "    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n",
        "\n",
        "    curves[0].append(acctrain)\n",
        "    curves[1].append(acctest)\n",
        "    curves[2].append(Ltrain)\n",
        "    curves[3].append(Ltest)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(curves[0], label=\"acc. train\")\n",
        "plt.plot(curves[1], label=\"acc. test\")\n",
        "plt.plot(curves[2], label=\"loss train\")\n",
        "plt.plot(curves[3], label=\"loss test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoFSrQNsJCnz"
      },
      "source": [
        "# Part 4 : Simplification of the SGD with `torch.optim`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8WtN9loJPqP"
      },
      "outputs": [],
      "source": [
        "def init_model(nx, nh, ny, eta):\n",
        "\n",
        "    #####################\n",
        "    ## Your code here  ##\n",
        "    #####################\n",
        "\n",
        "    model = None\n",
        "    loss = None\n",
        "    optim = None\n",
        "\n",
        "    ####################\n",
        "    ##      END        #\n",
        "    ####################\n",
        "\n",
        "    return model, loss, optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY-0rRzPJYDd"
      },
      "source": [
        "The `sgd` function is replaced by calling the `optim.zero_grad()` before the backward and `optim.step()` after."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q82hCupvJxvV"
      },
      "source": [
        "## Algorithme global d'apprentissage (avec autograd, les couches `torch.nn` et `torch.optim`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9h9nINKJ1LU"
      },
      "outputs": [],
      "source": [
        "# init\n",
        "data = CirclesData()\n",
        "data.plot_data()\n",
        "N = data.Xtrain.shape[0]\n",
        "Nbatch = 10\n",
        "nx = data.Xtrain.shape[1]\n",
        "nh = 10\n",
        "ny = data.Ytrain.shape[1]\n",
        "eta = 0.03\n",
        "\n",
        "model, loss, optim = init_model(nx, nh, ny, eta)\n",
        "\n",
        "curves = [[],[], [], []]\n",
        "\n",
        "# epoch\n",
        "for iteration in range(150):\n",
        "\n",
        "    # permute\n",
        "    perm = np.random.permutation(N)\n",
        "    Xtrain = data.Xtrain[perm, :]\n",
        "    Ytrain = data.Ytrain[perm, :]\n",
        "\n",
        "    #####################\n",
        "    ## Your code  here ##\n",
        "    #####################\n",
        "    # batches\n",
        "    for j in range(N // Nbatch):\n",
        "\n",
        "        indsBatch = range(j * Nbatch, (j+1) * Nbatch)\n",
        "        X = Xtrain[indsBatch, :]\n",
        "        Y = Ytrain[indsBatch, :]\n",
        "\n",
        "        # write the optimization algorithm on the batch (X,Y)\n",
        "        # using the functions: loss_accuracy\n",
        "        # the forward with the predict method from the model\n",
        "        # the backward function with autograd\n",
        "        # and then an optimization step\n",
        "\n",
        "    ####################\n",
        "    ##      FIN        #\n",
        "    ####################\n",
        "\n",
        "\n",
        "    Yhat_train = model(data.Xtrain)\n",
        "    Yhat_test = model(data.Xtest)\n",
        "    Ltrain, acctrain = loss_accuracy(loss, Yhat_train, data.Ytrain)\n",
        "    Ltest, acctest = loss_accuracy(loss, Yhat_test, data.Ytest)\n",
        "    Ygrid = model(data.Xgrid)\n",
        "\n",
        "    title = 'Iter {}: Acc train {:.1f}% ({:.2f}), acc test {:.1f}% ({:.2f})'.format(iteration, acctrain, Ltrain, acctest, Ltest)\n",
        "    print(title)\n",
        "    data.plot_data_with_grid(torch.nn.Softmax(dim=1)(Ygrid.detach()), title)\n",
        "\n",
        "    curves[0].append(acctrain)\n",
        "    curves[1].append(acctest)\n",
        "    curves[2].append(Ltrain)\n",
        "    curves[3].append(Ltest)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(curves[0], label=\"acc. train\")\n",
        "plt.plot(curves[1], label=\"acc. test\")\n",
        "plt.plot(curves[2], label=\"loss train\")\n",
        "plt.plot(curves[3], label=\"loss test\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts1s4JuOSaZ3"
      },
      "source": [
        "# Part 5 : MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jly9C4FCSzLP"
      },
      "source": [
        "Apply the code from previous part code to the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osrFoEr_Syi7"
      },
      "outputs": [],
      "source": [
        "# init\n",
        "data = MNISTData()\n",
        "N = data.Xtrain.shape[0]\n",
        "Nbatch = 100\n",
        "nx = data.Xtrain.shape[1]\n",
        "nh = 100\n",
        "ny = data.Ytrain.shape[1]\n",
        "eta = 0.03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRoiGbhvmSLO"
      },
      "source": [
        "# Part 6: Bonus: SVM\n",
        "\n",
        "\n",
        "Train a SVM model on the Circles dataset.\n",
        "\n",
        "Ideas :\n",
        "- First try a linear SVM (sklearn.svm.LinearSVC dans scikit-learn). Does it work well ? Why ?\n",
        "- Then try more complex kernels (sklearn.svm.SVC). Which one is the best ? why ?\n",
        "- Does the parameter C of regularization have an impact? Why ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWeW8siymR3g"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "data = CirclesData()\n",
        "Xtrain = data.Xtrain.numpy()\n",
        "Ytrain = data.Ytrain[:, 0].numpy()\n",
        "\n",
        "Xgrid = data.Xgrid.numpy()\n",
        "\n",
        "Xtest = data.Xtest.numpy()\n",
        "Ytest = data.Ytest[:, 0].numpy()\n",
        "\n",
        "def plot_svm_predictions(data, predictions):\n",
        "      plt.figure(2)\n",
        "      plt.clf()\n",
        "      plt.imshow(np.reshape(predictions, (40,40)))\n",
        "      plt.plot(data._Xtrain[data._Ytrain[:,0] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,0] == 1,1]*10+20, 'bo', label=\"Train\")\n",
        "      plt.plot(data._Xtrain[data._Ytrain[:,1] == 1,0]*10+20, data._Xtrain[data._Ytrain[:,1] == 1,1]*10+20, 'ro')\n",
        "      plt.plot(data._Xtest[data._Ytest[:,0] == 1,0]*10+20, data._Xtest[data._Ytest[:,0] == 1,1]*10+20, 'b+', label=\"Test\")\n",
        "      plt.plot(data._Xtest[data._Ytest[:,1] == 1,0]*10+20, data._Xtest[data._Ytest[:,1] == 1,1]*10+20, 'r+')\n",
        "      plt.xlim(0,39)\n",
        "      plt.ylim(0,39)\n",
        "      plt.clim(0.3,0.7)\n",
        "      plt.draw()\n",
        "      plt.pause(1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1xcE6zbmXU1"
      },
      "outputs": [],
      "source": [
        "import sklearn.svm\n",
        "\n",
        "############################\n",
        "### Your code here   #######\n",
        "### Train the SVM    #######\n",
        "## See https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
        "## and https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "############################\n",
        "\n",
        "svm = None\n",
        "\n",
        "###########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgLl7B_3mbOs"
      },
      "outputs": [],
      "source": [
        "## Print results\n",
        "\n",
        "Ytest_pred = svm.predict(Xtest)\n",
        "accuracy = np.sum(Ytest == Ytest_pred) / len(Ytest)\n",
        "print(f\"Accuracy : {100 * accuracy:.2f}\")\n",
        "Ygrid_pred = svm.predict(Xgrid)\n",
        "plot_svm_predictions(data, Ygrid_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
